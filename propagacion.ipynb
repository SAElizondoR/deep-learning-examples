{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SE DEFINE UNA RED NEURONAL CON LAS SIGUIENTES CARACTERÍSTICAS\n",
    "\n",
    "# 1. Una capa de entrada con dos neuronas (inputs) x1, x2\n",
    "# 2. Una capa oculta con 4 neuronas h1, h2, h3 y h4\n",
    "# 3. Una capa de salida con una neurona o1\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, n_inputs, n_hidden, n_output, learning_rate=0.1):\n",
    "        # Inicialización de pesos\n",
    "        self.weights_input_hidden = np.array([[0.2, 0.65, 0.45, 0.12],\n",
    "                                              [0.8, 0.35, 0.55, 0.15]])\n",
    "        self.weights_hidden_output = np.array([[0.2],\n",
    "                                               [0.35],\n",
    "                                               [0.45],\n",
    "                                               [0.52]])\n",
    "        self.bias_hidden = np.array([0.2, 0.15, 0.45, 0.52])\n",
    "        self.bias_output = 0.05\n",
    "        self.learning_rate = learning_rate  # Tasa de aprendizaje\n",
    "    \n",
    "    # Función de activación sigmoide\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    # Derivada de la función sigmoide\n",
    "    def sigmoidPrime(self, x):\n",
    "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
    "    \n",
    "    # Propagación hacia adelante\n",
    "    def forward_prop(self, x):\n",
    "        # Entrada a la capa oculta (z1)\n",
    "        z1 = np.dot(x, self.weights_input_hidden) + self.bias_hidden\n",
    "        print(\"Dimensiones de z1:\", z1.shape)\n",
    "\n",
    "        # Salida de la capa oculta\n",
    "        a1 = self.sigmoid(z1)\n",
    "        print(\"Dimensiones de a1:\", a1.shape)\n",
    "        \n",
    "        # Entrada a la capa de salida (z2)\n",
    "        z2 = np.dot(a1, self.weights_hidden_output) + self.bias_output\n",
    "        print(\"Dimensiones de z2:\", z2.shape)\n",
    "\n",
    "        # Salida final\n",
    "        output = self.sigmoid(z2)\n",
    "        print(\"Dimensiones de output:\", output.shape)\n",
    "\n",
    "        return z1, a1, z2, output\n",
    "    \n",
    "    # Propagación hacia atrás\n",
    "    def backward_prop(self, x, y, z1, a1, z2, output):\n",
    "        # Error en la capa de salida\n",
    "        error_output = output - y # Diferencia entre salida deseada y real\n",
    "        print(\"Dimensiones de error_output:\", error_output.shape)\n",
    "\n",
    "        # Gradiente de salida\n",
    "        delta_output = error_output * self.sigmoidPrime(z2) # 1x1\n",
    "        print(\"Dimensiones de delta_output:\", delta_output.shape)\n",
    "\n",
    "        # Gradiente de la capa oculta\n",
    "        error_hidden = delta_output.dot(self.weights_hidden_output.T)\n",
    "        print(\"Dimensiones de error_hidden:\", error_hidden.shape)\n",
    "\n",
    "        delta_hidden = error_hidden * self.sigmoidPrime(z1) # 1X1 1X4 1X4\n",
    "        print(\"Dimensiones de delta_hidden:\", delta_hidden.shape)\n",
    "        \n",
    "        # Actualización de pesos y sesgos\n",
    "        self.weights_hidden_output -= self.learning_rate * np.outer(a1, delta_output) # 4x1 1x1 = 4x1\n",
    "        self.bias_output -= self.learning_rate * delta_output\n",
    "\n",
    "        self.weights_input_hidden -= self.learning_rate * np.outer(x, delta_hidden)\n",
    "        self.bias_hidden -= self.learning_rate * delta_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialización la red neuronal\n",
    "n_inputs = 2 # Número de neuronas en la capa de entrada\n",
    "n_hidden = 4 # Número de neuronas en la capa oculta\n",
    "n_output = 1 # Número de neuornas en la capa de salida\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(n_inputs, n_hidden, n_output, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de entrenamiento\n",
    "x = np.array([0.25, 0.35])\n",
    "y = 4.5 # Valor de salida deseado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de z1: (4,)\n",
      "Dimensiones de a1: (4,)\n",
      "Dimensiones de z2: (1,)\n",
      "Dimensiones de output: (1,)\n",
      "Dimensiones de error_output: (1,)\n",
      "Dimensiones de delta_output: (1,)\n",
      "Dimensiones de error_hidden: (4,)\n",
      "Dimensiones de delta_hidden: (4,)\n",
      "Pesos de entrada a oculta después de la retropropagación:\n",
      "[[0.20085055 0.6515223  0.45178466 0.12216765]\n",
      " [0.80119076 0.35213121 0.55249852 0.1530347 ]]\n",
      "Pesos de oculta a salida después de la retropropagación:\n",
      "[[0.24591133]\n",
      " [0.39427641]\n",
      " [0.49961526]\n",
      " [0.56713262]]\n",
      "Sesgos de la capa oculta después de la retropropagación:\n",
      "[0.20340218 0.15608918 0.45713863 0.52867058]\n",
      "Sesgo de la capa de salida después de la retropropagación:\n",
      "[0.12293496]\n"
     ]
    }
   ],
   "source": [
    "# Propagación hacia adelante\n",
    "z1, a1, z2, y_hat = nn.forward_prop(x)\n",
    "\n",
    "# Realizar la retropropagación\n",
    "nn.backward_prop(x, y, z1, a1, z2, y_hat)\n",
    "\n",
    "# Mostrar pesos y sesgos actualizados\n",
    "print(\"Pesos de entrada a oculta después de la retropropagación:\")\n",
    "print(nn.weights_input_hidden)\n",
    "print(\"Pesos de oculta a salida después de la retropropagación:\")\n",
    "print(nn.weights_hidden_output)\n",
    "print(\"Sesgos de la capa oculta después de la retropropagación:\")\n",
    "print(nn.bias_hidden)\n",
    "print(\"Sesgo de la capa de salida después de la retropropagación:\")\n",
    "print(nn.bias_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
